{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why codde? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***SigLIP Hyper Tuning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:10:42.050557Z",
     "iopub.status.busy": "2025-01-19T18:10:42.050288Z",
     "iopub.status.idle": "2025-01-19T18:10:45.233045Z",
     "shell.execute_reply": "2025-01-19T18:10:45.231883Z",
     "shell.execute_reply.started": "2025-01-19T18:10:42.050528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "from tqdm import tqdm \n",
    "print(\"Oke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Down dataset from the my hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:10:45.234906Z",
     "iopub.status.busy": "2025-01-19T18:10:45.234361Z",
     "iopub.status.idle": "2025-01-19T18:10:49.388713Z",
     "shell.execute_reply": "2025-01-19T18:10:49.387769Z",
     "shell.execute_reply.started": "2025-01-19T18:10:45.234863Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:10:49.389950Z",
     "iopub.status.busy": "2025-01-19T18:10:49.389621Z",
     "iopub.status.idle": "2025-01-19T18:13:51.317773Z",
     "shell.execute_reply": "2025-01-19T18:13:51.317113Z",
     "shell.execute_reply.started": "2025-01-19T18:10:49.389924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "source_data = load_dataset(\"QuanHoangNgoc/MS-Flick\")\n",
    "source_data = source_data[\"test\"]\n",
    "source_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model: CLIP, SigLIP, Prepare stage: Build Mdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:13:51.319299Z",
     "iopub.status.busy": "2025-01-19T18:13:51.318740Z",
     "iopub.status.idle": "2025-01-19T18:14:21.911640Z",
     "shell.execute_reply": "2025-01-19T18:14:21.910399Z",
     "shell.execute_reply.started": "2025-01-19T18:13:51.319274Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoProcessor, AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "class SigLipEncoder:\n",
    "    def __init__(self):\n",
    "        self.Model = AutoModel.from_pretrained(\"google/siglip-base-patch16-224\")\n",
    "        self.Processor = AutoProcessor.from_pretrained(\"google/siglip-base-patch16-224\")\n",
    "        self.Tokenizer = AutoTokenizer.from_pretrained(\"google/siglip-base-patch16-224\")\n",
    "\n",
    "    def form_model(self, dtype=None, device=None, grad_mode=False, eval_model=True):\n",
    "        \"\"\"Moves and converts the model to the specified dtype and device.\"\"\"\n",
    "        self.Model.to(dtype=dtype, device=device)\n",
    "        for param in self.Model.parameters():\n",
    "            param.requires_grad = grad_mode   \n",
    "        if(eval_model): \n",
    "            self.Model.eval() \n",
    "        return self\n",
    "\n",
    "    def infor_model(self): \n",
    "        cnt = 0 \n",
    "        params = [(name, param) for name, param in self.Model.named_parameters()]\n",
    "        for name, param in params:\n",
    "            cnt += 1 \n",
    "            if(cnt < 3 or cnt > len(params) - 3): \n",
    "                print(f\"Parameter: {name}\")\n",
    "                print(f\"  Data type: {param.dtype}\")\n",
    "                print(f\"  Requires gradient: {param.requires_grad}\")\n",
    "                print(f\"  Device: {param.device}\")\n",
    "                print(\"-\" * 20)  # Separator for readability\n",
    "\n",
    "    def form_ts(self, inputs_dict):\n",
    "        dtype = self.Model.dtype\n",
    "        device = self.Model.device\n",
    "        for key, value in inputs_dict.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                inputs_dict[key] = value.to(device=device)\n",
    "                if dtype is not None and value.dtype.is_floating_point: #only convert float tensor\n",
    "                    inputs_dict[key] = inputs_dict[key].type(dtype)\n",
    "        return inputs_dict\n",
    "\n",
    "    def get_np_text(self, str_chunk):\n",
    "        inputs_ts = self.Tokenizer(str_chunk, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        inputs_ts = self.form_ts(inputs_ts)\n",
    "        with torch.inference_mode():\n",
    "            text_features = self.Model.get_text_features(**inputs_ts).cpu().numpy()  # Move to CPU before converting to NumPy\n",
    "        return text_features\n",
    "\n",
    "    def get_np_image(self, pil_chunk):\n",
    "        inputs_ts = self.Processor(images=pil_chunk, return_tensors=\"pt\")\n",
    "        inputs_ts = self.form_ts(inputs_ts)\n",
    "        with torch.inference_mode():\n",
    "            image_features = self.Model.get_image_features(**inputs_ts).cpu().numpy()  # Move to CPU before converting to NumPy\n",
    "        return image_features\n",
    "\n",
    "\n",
    "siglip = SigLipEncoder() \n",
    "siglip = siglip.form_model(dtype=torch.float32, device='cuda') \n",
    "siglip.infor_model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:14:21.913556Z",
     "iopub.status.busy": "2025-01-19T18:14:21.912737Z",
     "iopub.status.idle": "2025-01-19T18:14:22.218217Z",
     "shell.execute_reply": "2025-01-19T18:14:22.217386Z",
     "shell.execute_reply.started": "2025-01-19T18:14:21.913519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "siglip.get_np_text(\"people\").shape # testcase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:14:22.220334Z",
     "iopub.status.busy": "2025-01-19T18:14:22.220110Z",
     "iopub.status.idle": "2025-01-19T18:14:25.218720Z",
     "shell.execute_reply": "2025-01-19T18:14:25.217748Z",
     "shell.execute_reply.started": "2025-01-19T18:14:22.220308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "source_data[0][\"image\"] # tescase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:14:25.220210Z",
     "iopub.status.busy": "2025-01-19T18:14:25.219905Z",
     "iopub.status.idle": "2025-01-19T18:22:50.490938Z",
     "shell.execute_reply": "2025-01-19T18:22:50.490002Z",
     "shell.execute_reply.started": "2025-01-19T18:14:25.220175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def build_M_db(ds, encoder, batch_size=64):\n",
    "    \"\"\"\n",
    "    Build the M database by encoding images in batches for faster processing.\n",
    "    \n",
    "    Args:\n",
    "        ds: Dataset containing image data.\n",
    "        encoder: Encoder object with a `get_np_image` method.\n",
    "        batch_size: Number of images to process per batch.\n",
    "    \n",
    "    Returns:\n",
    "        M: Numpy array of encoded image representations.\n",
    "    \"\"\"\n",
    "    M = []\n",
    "\n",
    "    # Preprocess data in batches\n",
    "    for start_idx in tqdm(range(0, len(ds), batch_size), desc=\"Processing Batches\"):\n",
    "        # Get a batch of images\n",
    "        batch = [ds[i][\"image\"] for i in range(start_idx, min(start_idx + batch_size, len(ds)))]\n",
    "\n",
    "        # Encode the batch (assumes `get_np_image` can process a list of images)\n",
    "        enc_np_batch = encoder.get_np_image(batch)  # Ensure encoder supports batch processing\n",
    "\n",
    "        # Add encoded batch to M\n",
    "        M.append(enc_np_batch)\n",
    "\n",
    "    # Convert list of batches to a single NumPy array\n",
    "    M = np.vstack(M)\n",
    "    return M\n",
    "\n",
    "\n",
    "Mdb = build_M_db(source_data, siglip) #[warn] long run\n",
    "print(Mdb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval stage, Iterative feedback loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:25:17.846600Z",
     "iopub.status.busy": "2025-01-19T18:25:17.846268Z",
     "iopub.status.idle": "2025-01-19T18:25:17.851134Z",
     "shell.execute_reply": "2025-01-19T18:25:17.850367Z",
     "shell.execute_reply.started": "2025-01-19T18:25:17.846577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_ordered(query_enc, Mdb):\n",
    "    \"\"\"\n",
    "    Computes cosine similarity between the encoded text and Mdb,\n",
    "    and returns an ordered list of indices based on similarity.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "        encoder (SigLipEncoder): The encoder object.\n",
    "        Mdb (np.ndarray): The database of encoded vectors.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of indices sorted by cosine similarity.\n",
    "    \"\"\"\n",
    "    similarities = cosine_similarity(query_enc.reshape(1, -1), Mdb)  # Reshape enc_np for cosine_similarity\n",
    "    ordered_indices = np.argsort(similarities[0])[::-1]  # Sort in descending order\n",
    "    return ordered_indices\n",
    "\n",
    "def representation(text, encoder): \n",
    "    query_enc = encoder.get_np_text(text)[0] \n",
    "    return query_enc \n",
    "\n",
    "# q = representation(\"people\", siglip)\n",
    "# order = get_ordered(q, Mdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:26:10.562052Z",
     "iopub.status.busy": "2025-01-19T18:26:10.561733Z",
     "iopub.status.idle": "2025-01-19T18:26:10.770287Z",
     "shell.execute_reply": "2025-01-19T18:26:10.769416Z",
     "shell.execute_reply.started": "2025-01-19T18:26:10.562028Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_centroid(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, list):\n",
    "        return np.stack(x, dim = 0).mean(0)\n",
    "    else:\n",
    "    # elif isinstance(x, np.) and x.ndim == 2:\n",
    "        return np.mean(x, 0)\n",
    "    \n",
    "def rocchio_relevance_feedback(query = None, positive = None, negative = None, alpha = 1, beta = 0.8, gamma = 0.1):\n",
    "    \"\"\"\n",
    "        Rocchio algorithm for relevance feedback as follows:\n",
    "            newQuery = alpha * query + beta * centroid(positive) - gamma * centroid(negative)\n",
    "        Args:\n",
    "            query:\n",
    "            positive:\n",
    "            negative:\n",
    "            alpha, beta, gamma: \n",
    "        Returns: \n",
    "            newQuery: \n",
    "    \"\"\"\n",
    "    # print(\"Rocchio relevance feedback\", end=\" [>] \")\n",
    "    \n",
    "    newQuery = query * alpha \n",
    "    if positive is not None: newQuery += beta * get_centroid(positive)\n",
    "    if negative is not None: newQuery -= gamma * get_centroid(negative) \n",
    "    return newQuery\n",
    "\n",
    "def iterative_loop(text, encoder, Mdb, number=1, top_positive = 3): \n",
    "    q = representation(text, encoder)\n",
    "    order = get_ordered(q, Mdb)\n",
    "\n",
    "    # top_positive = 3 \n",
    "    for nth in range(number): \n",
    "        q = rocchio_relevance_feedback(q, Mdb[order[:top_positive]], Mdb[order[-top_positive:]]) #!!! set hypo \n",
    "        # q = rocchio_relevance_feedback(q, Mdb[order[:top_positive]]) #!!! set hypo \n",
    "        order = get_ordered(q, Mdb)\n",
    "    # print(f\"{number} [\\\\]\") \n",
    "    return order \n",
    "\n",
    "iterative_loop(\"red people\", siglip, Mdb, number=1) # [0, n-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Exp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:37:43.769423Z",
     "iopub.status.busy": "2025-01-19T18:37:43.769096Z",
     "iopub.status.idle": "2025-01-19T18:37:45.636616Z",
     "shell.execute_reply": "2025-01-19T18:37:45.635742Z",
     "shell.execute_reply.started": "2025-01-19T18:37:43.769395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def eval_epoch(ds, selected_idx, encoder, Mdb, number_hp, breaking_rank = 1, top_positive=3):\n",
    "    ranks = []\n",
    "    print(f\"[+] Len test: {len(selected_idx)}\")\n",
    "    for idx in tqdm(selected_idx):\n",
    "        captions = ds[idx][\"caption\"].split(\"@\")\n",
    "        # Access captions for the current index\n",
    "        for cap in captions:\n",
    "            try:\n",
    "                for N in range(0, number_hp + 1): \n",
    "                    order = iterative_loop(cap, encoder, Mdb, number=N, top_positive = top_positive)  # [0, n-1]\n",
    "                    rank = np.where(order == idx)[0][0] # changed from order.index(idx) to np.where(order == idx)[0][0]\n",
    "                    if(rank < breaking_rank): break \n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(e) \n",
    "                rank = 100000 # not found\n",
    "\n",
    "            ranks.append(rank)\n",
    "\n",
    "    ranks = np.array(ranks)\n",
    "    r1 = 100.0 * len(np.where(ranks < 1)[0]) / len(ranks)\n",
    "    r5 = 100.0 * len(np.where(ranks < 5)[0]) / len(ranks)\n",
    "    r10 = 100.0 * len(np.where(ranks < 10)[0]) / len(ranks)\n",
    "    medr = np.floor(np.median(ranks)) + 1\n",
    "    meanr = ranks.mean() + 1\n",
    "    \n",
    "    print(f\"[+] Text to image ({len(ranks)}): Number={number_hp}\")\n",
    "    print(\"\\tTop_positive: {}\".format(top_positive))\n",
    "    print(\"\\tBreaking_rank: {}\".format(breaking_rank))\n",
    "    print(\"\\tR@1: {:.4f}\".format(r1))\n",
    "    print(\"\\tR@5: {:.4f}\".format(r5))\n",
    "    print(\"\\tR@10: {:.4f}\".format(r10))\n",
    "    print(\"\\tMed r: {:.4f}\".format(medr))\n",
    "    print(\"\\tMean r: {:.4f}\".format(meanr))\n",
    "\n",
    "    return (r1, r5, r10, medr, meanr)\n",
    "\n",
    "\n",
    "selected_idx = [i for i in range(5001, len(source_data)) if i % 300 == 0]\n",
    "print(len(selected_idx))\n",
    "selected_idx += [i for i in range(0, 5001) if i % 50 == 0]\n",
    "print(len(selected_idx))\n",
    "eval_epoch(source_data, [0, 1], siglip, Mdb, number_hp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T18:37:55.079061Z",
     "iopub.status.busy": "2025-01-19T18:37:55.078590Z",
     "iopub.status.idle": "2025-01-19T19:01:44.623567Z",
     "shell.execute_reply": "2025-01-19T19:01:44.622253Z",
     "shell.execute_reply.started": "2025-01-19T18:37:55.079020Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import signal\n",
    "import time\n",
    "\n",
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutException(\"Function call timed out\")\n",
    "\n",
    "def eval_epoch_with_timeout(ds, selected_idx, encoder, Mdb, number_hp, timeout_seconds=60 * 60, breaking_rank = 1, top_positive=3):\n",
    "    # Set the signal handler and a 2-minute alarm\n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    signal.alarm(timeout_seconds)\n",
    "    \n",
    "    try:\n",
    "        return eval_epoch(ds, selected_idx, encoder, Mdb, number_hp, breaking_rank = breaking_rank, top_positive= top_positive) #!!! original eval_epoch function\n",
    "    except TimeoutException:\n",
    "        print(\"Evaluation timed out after 2 minutes\")\n",
    "        return None # or some default value\n",
    "    finally:\n",
    "        signal.alarm(0) # Disable the alarm\n",
    "\n",
    "\n",
    "top_positive_list = [3, 5, 10, 15]\n",
    "breaking_rank_list = [1, 5, 10, 15]\n",
    "\n",
    "for top_positive in top_positive_list:\n",
    "    for breaking_rank in breaking_rank_list:\n",
    "\n",
    "        lis = [] \n",
    "        for number in range(0, 3):\n",
    "            tup = eval_epoch_with_timeout(source_data, selected_idx, siglip, Mdb, number_hp=number, breaking_rank = breaking_rank, top_positive=top_positive)\n",
    "            lis.append(tup)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
